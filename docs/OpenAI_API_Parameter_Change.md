# OpenAI API åƒæ•¸è®Šæ›´èªªæ˜

> **æ—¥æœŸ**ï¼š2024-12-23  
> **å½±éŸ¿ç¯„åœ**ï¼šæ‰€æœ‰ä½¿ç”¨ OpenAI GPT-4 åŠä»¥ä¸Šæ¨¡å‹çš„åŠŸèƒ½  
> **åš´é‡ç¨‹åº¦**ï¼šğŸ”´ é«˜ï¼ˆä¸ä¿®æ­£å°‡å°è‡´ API å‘¼å«å¤±æ•—ï¼‰

---

## ğŸ“‹ è®Šæ›´æ‘˜è¦

### å•é¡Œ 1ï¼šmax_tokens åƒæ•¸ä¸æ”¯æ´

OpenAI æ–°ç‰ˆ APIï¼ˆç‰¹åˆ¥æ˜¯ GPT-4ã€GPT-4o ç³»åˆ—æ¨¡å‹ï¼‰ä¸å†æ”¯æ´ `max_tokens` åƒæ•¸ã€‚

### éŒ¯èª¤è¨Šæ¯ 1

```json
{
  "error": {
    "message": "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.",
    "type": "invalid_request_error",
    "param": "max_tokens",
    "code": "unsupported_parameter"
  }
}
```

### è§£æ±ºæ–¹æ¡ˆ 1

å°‡ `max_tokens` åƒæ•¸æ”¹ç‚º `max_completion_tokens`ã€‚

---

### å•é¡Œ 2ï¼štemperature åƒæ•¸ä¸æ”¯æ´è‡ªè¨‚å€¼

æŸäº› OpenAI æ¨¡å‹ï¼ˆå¦‚ gpt-4oï¼‰ä¸æ”¯æ´è‡ªè¨‚ temperatureï¼Œåªèƒ½ä½¿ç”¨é è¨­å€¼ 1ã€‚

### éŒ¯èª¤è¨Šæ¯ 2

```json
{
  "error": {
    "message": "Unsupported value: 'temperature' does not support 0.3 with this model. Only the default (1) value is supported.",
    "type": "invalid_request_error",
    "param": "temperature",
    "code": "unsupported_value"
  }
}
```

### è§£æ±ºæ–¹æ¡ˆ 2

ä¸å‚³é€ temperature åƒæ•¸ï¼Œè®“ API ä½¿ç”¨æ¨¡å‹çš„é è¨­å€¼ã€‚

---

### å•é¡Œ 3ï¼šä½¿ç”¨ JSON æ ¼å¼æ™‚å¿…é ˆåœ¨ messages ä¸­æåŠ "json"

ç•¶ä½¿ç”¨ `response_format: { type: 'json_object' }` æ™‚ï¼ŒOpenAI è¦æ±‚ messages ä¸­å¿…é ˆåŒ…å« "json" é€™å€‹è©ã€‚

### éŒ¯èª¤è¨Šæ¯ 3

```json
{
  "error": {
    "message": "'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.",
    "type": "invalid_request_error",
    "param": "messages",
    "code": null
  }
}
```

### è§£æ±ºæ–¹æ¡ˆ 3

åœ¨ system message æˆ– user message ä¸­æ˜ç¢ºæåŠ "JSON" æ ¼å¼ã€‚

---

## ğŸ”§ ä¿®æ­£å…§å®¹

### Edge Function ä¿®æ­£

**æª”æ¡ˆ**ï¼š`/supabase/functions/server/index.tsx`

#### ä¿®æ­£å‰ï¼ˆéŒ¯èª¤ï¼‰

```typescript
body: JSON.stringify({
  model,
  messages,
  temperature: temperature || 0.3,  // âŒ æŸäº›æ¨¡å‹ä¸æ”¯æ´è‡ªè¨‚å€¼
  max_tokens: maxTokens || 1000,    // âŒ èˆŠç‰ˆåƒæ•¸
  response_format: { type: 'json_object' }
})
```

#### ä¿®æ­£å¾Œï¼ˆæ­£ç¢ºï¼‰

```typescript
// å»ºç«‹è«‹æ±‚ bodyï¼Œä¸åŒ…å« temperatureï¼ˆä½¿ç”¨é è¨­å€¼ï¼‰
const requestBody: any = {
  model,
  messages,
  max_completion_tokens: maxTokens || 1000,  // âœ… æ–°ç‰ˆåƒæ•¸
  response_format: { type: 'json_object' }
};
// temperature ä¸å‚³é€ï¼Œè®“æ¨¡å‹ä½¿ç”¨é è¨­å€¼

body: JSON.stringify(requestBody)
```

---

## ğŸ“Š åƒæ•¸å°ç…§è¡¨

| Provider | èˆŠç‰ˆåƒæ•¸ | æ–°ç‰ˆåƒæ•¸ | ç‹€æ…‹ |
|----------|----------|----------|------|
| OpenAI (GPT-4+) | `max_tokens` | `max_completion_tokens` | âœ… å·²ä¿®æ­£ |
| OpenAI (GPT-3.5) | `max_tokens` | `max_tokens` | â„¹ï¸ ä»æ”¯æ´èˆŠç‰ˆ |
| Anthropic | `max_tokens` | `max_tokens` | âœ… ç„¡éœ€ä¿®æ”¹ |
| Google Gemini | `maxOutputTokens` | `maxOutputTokens` | âœ… ç„¡éœ€ä¿®æ”¹ |

---

## ğŸ¯ å½±éŸ¿ç¯„åœ

### å·²ä¿®æ­£çš„æª”æ¡ˆ

1. âœ… `/supabase/functions/server/index.tsx`ï¼ˆEdge Functionï¼‰
   - OpenAI API å‘¼å«å·²æ›´æ–°ç‚º `max_completion_tokens`
   - Anthropic API ä¿æŒä½¿ç”¨ `max_tokens`

### ç„¡éœ€ä¿®æ”¹çš„æª”æ¡ˆ

- `/src/lib/ai/AIService.ts`ï¼šåƒ…è² è²¬å‘¼å« Edge Functionï¼Œåƒæ•¸åç¨±ç”± Edge Function è™•ç†
- `/src/hooks/useAIChat.ts`ï¼šåƒ…è² è²¬å‘¼å« AIServiceï¼Œç„¡éœ€ä¿®æ”¹
- `/src/app/settings/AISettingsPage.tsx`ï¼šåƒ…è² è²¬è¨­å®šå„²å­˜ï¼Œç„¡éœ€ä¿®æ”¹

---

## ğŸ§ª æ¸¬è©¦é©—è­‰

### æ¸¬è©¦æ­¥é©Ÿ

1. **é‡æ–°éƒ¨ç½² Edge Function**
   ```bash
   supabase functions deploy make-server-4df51a95
   ```

2. **é€²å…¥ AI è¨­å®šé é¢**
   - è·¯å¾‘ï¼šè¨­å®š â†’ ç³»çµ±ç®¡ç† â†’ AI è¨­å®š

3. **æ¸¬è©¦é€£ç·š**
   - é¸æ“‡ OpenAI ä¾›æ‡‰å•†
   - é¸æ“‡ GPT-4 æˆ– GPT-4o æ¨¡å‹
   - è¼¸å…¥æœ‰æ•ˆçš„ API Key
   - é»æ“Šã€Œæ¸¬è©¦é€£ç·šã€

4. **é æœŸçµæœ**
   - âœ… æ¸¬è©¦æˆåŠŸï¼Œé¡¯ç¤ºã€Œâœ… æˆåŠŸé€£ç·šè‡³ openai gpt-4ã€
   - âŒ ä¸å†å‡ºç¾ã€ŒUnsupported parameterã€éŒ¯èª¤

### æ¸¬è©¦æ—¥èªŒ

æˆåŠŸçš„æ—¥èªŒæ‡‰è©²å¦‚ä¸‹ï¼š

```
ğŸ§ª æ¸¬è©¦ openai API é€£ç·š...
ğŸ“¡ å‘¼å« Edge Function: https://xxx.supabase.co/functions/v1/make-server-4df51a95/ai/chat
âœ… AI API æ¸¬è©¦æˆåŠŸ: { 
  choices: [...],
  usage: { completion_tokens: ..., prompt_tokens: ..., total_tokens: ... }
}
```

---

## ğŸ“š OpenAI å®˜æ–¹èªªæ˜

### åƒæ•¸å®šç¾©

#### `max_completion_tokens` (æ–°ç‰ˆ)

> The maximum number of tokens that can be generated in the chat completion. The total length of input tokens and generated tokens is limited by the model's context length.

**ç‰¹é»**ï¼š
- åƒ…è¨ˆç®—ã€Œç”Ÿæˆã€çš„ tokensï¼ˆä¸åŒ…å« input tokensï¼‰
- æ›´ç²¾ç¢ºçš„ token æ§åˆ¶
- GPT-4 åŠä»¥ä¸Šæ¨¡å‹å¿…é ˆä½¿ç”¨æ­¤åƒæ•¸

#### `max_tokens` (èˆŠç‰ˆ)

> Legacy parameter. Use `max_completion_tokens` instead.

**ç‹€æ…‹**ï¼š
- GPT-3.5 åŠèˆŠç‰ˆæ¨¡å‹ä»æ”¯æ´
- GPT-4 åŠä»¥ä¸Šæ¨¡å‹å·²æ£„ç”¨

---

## âš ï¸ æ³¨æ„äº‹é …

### 1. æ¨¡å‹ç‰ˆæœ¬å·®ç•°

ä¸åŒçš„ OpenAI æ¨¡å‹å°åƒæ•¸çš„æ”¯æ´ç¨‹åº¦ä¸åŒï¼š

#### Token é™åˆ¶æ•¸

| æ¨¡å‹ | `max_tokens` | `max_completion_tokens` | ç‹€æ…‹ |
|------|--------------|-------------------------|------|
| GPT-4o | âŒ ä¸æ”¯æ´ | âœ… å¿…é ˆä½¿ç”¨ | å·²ä¿®æ­£ |
| GPT-4o-mini | âŒ ä¸æ”¯æ´ | âœ… å¿…é ˆä½¿ç”¨ | å·²ä¿®æ­£ |
| GPT-4 | âŒ ä¸æ”¯æ´ | âœ… å¿…é ˆä½¿ç”¨ | å·²ä¿®æ­£ |
| GPT-4 Turbo | âŒ ä¸æ”¯æ´ | âœ… å¿…é ˆä½¿ç”¨ | å·²ä¿®æ­£ |
| GPT-3.5 Turbo | âœ… æ”¯æ´ | âœ… æ”¯æ´ | ç„¡éœ€ä¿®æ”¹ |

#### Temperature åƒæ•¸

| æ¨¡å‹ | æ”¯æ´è‡ªè¨‚ temperature | é è¨­å€¼ | èªªæ˜ |
|------|---------------------|--------|------|
| GPT-4o | âŒ å¦ | 1 | åªèƒ½ä½¿ç”¨é è¨­å€¼ |
| GPT-4o-mini | âŒ å¦ | 1 | åªèƒ½ä½¿ç”¨é è¨­å€¼ |
| GPT-4 | âœ… æ˜¯ | 1 | å¯è‡ªè¨‚ 0-2 |
| GPT-4 Turbo | âœ… æ˜¯ | 1 | å¯è‡ªè¨‚ 0-2 |
| GPT-3.5 Turbo | âœ… æ˜¯ | 1 | å¯è‡ªè¨‚ 0-2 |

**ç›®å‰å¯¦ä½œ**ï¼šä¸å‚³é€ temperature åƒæ•¸ï¼Œè®“æ‰€æœ‰æ¨¡å‹ä½¿ç”¨é è¨­å€¼ï¼ˆå‘ä¸‹ç›¸å®¹ï¼‰

### 2. å…¶ä»– AI ä¾›æ‡‰å•†

- **Anthropic**ï¼šä»ä½¿ç”¨ `max_tokens`ï¼Œç„¡éœ€ä¿®æ”¹
- **Google Gemini**ï¼šä½¿ç”¨ `maxOutputTokens`ï¼Œç„¡éœ€ä¿®æ”¹

### 3. å‘ä¸‹ç›¸å®¹æ€§

ç‚ºäº†æ”¯æ´èˆŠç‰ˆæ¨¡å‹ï¼ˆå¦‚ GPT-3.5ï¼‰ï¼Œå¯ä»¥è€ƒæ…®å¯¦ä½œä»¥ä¸‹é‚è¼¯ï¼š

```typescript
// æ ¹æ“šæ¨¡å‹ç‰ˆæœ¬é¸æ“‡åƒæ•¸ï¼ˆæœªä¾†æ”¹é€²æ–¹æ¡ˆï¼‰
const isLegacyModel = model.includes('gpt-3.5');
const tokenParam = isLegacyModel 
  ? { max_tokens: maxTokens || 1000 }
  : { max_completion_tokens: maxTokens || 1000 };

body: JSON.stringify({
  model,
  messages,
  temperature: temperature || 0.3,
  ...tokenParam,
  response_format: { type: 'json_object' }
})
```

---

## ğŸ”— ç›¸é—œè³‡æº

- [OpenAI API Reference - Chat Completions](https://platform.openai.com/docs/api-reference/chat/create)
- [OpenAI Migration Guide](https://platform.openai.com/docs/guides/migration)
- [æœ¬å°ˆæ¡ˆ AI æ•´åˆæ–‡ä»¶](/docs/AI_ChatGPT_Integration_Complete.md)

---

## âœ… é©—æ”¶æ¸…å–®

- [x] âœ… Edge Function å·²ä¿®æ­£ç‚ºä½¿ç”¨ `max_completion_tokens`
- [x] âœ… Edge Function å·²ç§»é™¤ `temperature` åƒæ•¸ï¼ˆä½¿ç”¨é è¨­å€¼ï¼‰
- [x] âœ… æ¸¬è©¦è¨Šæ¯ä¸­åŒ…å« "JSON" é—œéµè©
- [x] âœ… Anthropic API å‘¼å«ä¿æŒä½¿ç”¨ `max_tokens`
- [x] âœ… Edge Function å·²é‡æ–°éƒ¨ç½²
- [x] âœ… GPT-4 æ¨¡å‹æ¸¬è©¦é€£ç·šæˆåŠŸ
- [x] âœ… æ–‡æª”å·²æ›´æ–°

---

**æ–‡ä»¶ç‰ˆæœ¬**ï¼šv1.0  
**æœ€å¾Œæ›´æ–°**ï¼š2024-12-23  
**æ›´æ–°è€…**ï¼šAI Assistant